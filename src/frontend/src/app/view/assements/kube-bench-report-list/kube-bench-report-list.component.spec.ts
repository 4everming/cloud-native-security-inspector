import { CUSTOM_ELEMENTS_SCHEMA, NO_ERRORS_SCHEMA } from '@angular/core';
import { ComponentFixture, fakeAsync, TestBed, tick } from '@angular/core/testing';
import { Observable, of } from 'rxjs';
import { AssessmentService } from 'src/app/service/assessment.service';
import { PolicyService } from 'src/app/service/policy.service';
import { ShardService } from 'src/app/service/shard.service';
import { ShardTestModule } from 'src/app/shard/shard/shard.module';

import { KubeBenchReportListComponent } from './kube-bench-report-list.component';

describe('KubeBenchReportListComponent', () => {
  let component: KubeBenchReportListComponent;
  let fixture: ComponentFixture<KubeBenchReportListComponent>;
  let policyService: PolicyService
  let shardService: ShardService
  let assessmentService: AssessmentService
  const cnsiServiceStub: any = {
    getNodeList() {
      return of({
        "items": [
          {
            "metadata": {
              "name": "sc2-10-186-131-84.eng.vmware.com",
            },
          },
          {
            "metadata": {
              "name": "sc2-10-186-134-223.eng.vmware.com",
            },
          },
          {
            "metadata": {
              "name": "sc2-10-186-142-227.eng.vmware.com",
            },
          }
        ]
      });
    },
    getInspectionpolicies(): Observable<any> {
      return of(
        {"items":[{"spec":{"inspector":{"imagePullPolicy":"IfNotPresent","kubebenchImage":"projects.registry.vmware.com/cnsi/kubebench:0.3"}}}],}
      )
    },
    getPodList() {
      return of({
        "items": [
          {
            "metadata": {
              "name": "inspectionpolicy-sample-kubebench-daemonset-7qjdg",
            }
          },
          {
            "metadata": {
              "name": "inspectionpolicy-sample-kubebench-daemonset-s2dql",
            }
          },
          {
            "metadata": {
              "name": "inspectionpolicy-sample-kubebench-daemonset-zb882",
            }
          }
        ]
      })
    },
    getKubeBenchReport() {
      return of({"took":52,"timed_out":false,"_shards":{"total":1,"successful":1,"skipped":0,"failed":0},"hits":{"total":{"value":2,"relation":"eq"},"max_score":null,"hits":[{"_index":"cis_report","_id":"kubebench-Report_2023-02-15T15:19:14Z_4q7dm","_score":null,"_source":{"id":"4","version":"cis-1.20","detected_version":"1.21","text":"Worker Node Security Configuration","node_type":"node","tests":[{"section":"4.1","type":"","pass":10,"fail":0,"warn":0,"info":0,"desc":"Worker Node Configuration Files","results":[{"test_number":"4.1.1","test_desc":"Ensure that the kubelet service file permissions are set to 644 or more restrictive (Automated)","audit":"/bin/sh -c 'if test -e /lib/systemd/system/kubelet.service; then stat -c permissions=%a /lib/systemd/system/kubelet.service; fi' ","AuditEnv":"","AuditConfig":"","type":"","remediation":"Run the below command (based on the file location on your system) on the each worker node.\nFor example,\nchmod 644 /lib/systemd/system/kubelet.service\n","test_info":["Run the below command (based on the file location on your system) on the each worker node.\nFor example,\nchmod 644 /lib/systemd/system/kubelet.service\n"],"status":"PASS","actual_value":"permissions=644","scored":true,"IsMultiple":false,"expected_result":"permissions has permissions 644, expected 644 or more restrictive"},{"test_number":"4.1.2","test_desc":"Ensure that the kubelet service file ownership is set to root:root (Automated)","audit":"/bin/sh -c 'if test -e /lib/systemd/system/kubelet.service; then stat -c %U:%G /lib/systemd/system/kubelet.service; fi' ","AuditEnv":"","AuditConfig":"","type":"","remediation":"Run the below command (based on the file location on your system) on the each worker node.\nFor example,\nchown root:root /lib/systemd/system/kubelet.service\n","test_info":["Run the below command (based on the file location on your system) on the each worker node.\nFor example,\nchown root:root /lib/systemd/system/kubelet.service\n"],"status":"PASS","actual_value":"root:root","scored":true,"IsMultiple":false,"expected_result":"'root:root' is present"},{"test_number":"4.1.3","test_desc":"If proxy kubeconfig file exists ensure permissions are set to 644 or more restrictive (Manual)","audit":"/bin/sh -c 'if test -e /etc/kubernetes/proxy.conf; then stat -c permissions=%a /etc/kubernetes/proxy.conf; fi' ","AuditEnv":"","AuditConfig":"","type":"","remediation":"Run the below command (based on the file location on your system) on the each worker node.\nFor example,\nchmod 644 /etc/kubernetes/proxy.conf\n","test_info":["Run the below command (based on the file location on your system) on the each worker node.\nFor example,\nchmod 644 /etc/kubernetes/proxy.conf\n"],"status":"PASS","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"'permissions' is present OR '/etc/kubernetes/proxy.conf' is not present"},{"test_number":"4.1.4","test_desc":"If proxy kubeconfig file exists ensure ownership is set to root:root (Manual)","audit":"/bin/sh -c 'if test -e /etc/kubernetes/proxy.conf; then stat -c %U:%G /etc/kubernetes/proxy.conf; fi' ","AuditEnv":"","AuditConfig":"","type":"","remediation":"Run the below command (based on the file location on your system) on the each worker node.\nFor example, chown root:root /etc/kubernetes/proxy.conf\n","test_info":["Run the below command (based on the file location on your system) on the each worker node.\nFor example, chown root:root /etc/kubernetes/proxy.conf\n"],"status":"PASS","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"'root:root' is present OR '/etc/kubernetes/proxy.conf' is not present"},{"test_number":"4.1.5","test_desc":"Ensure that the --kubeconfig kubelet.conf file permissions are set to 644 or more restrictive (Automated)","audit":"/bin/sh -c 'if test -e /etc/kubernetes/kubelet.conf; then stat -c permissions=%a /etc/kubernetes/kubelet.conf; fi' ","AuditEnv":"","AuditConfig":"","type":"","remediation":"Run the below command (based on the file location on your system) on the each worker node.\nFor example,\nchmod 644 /etc/kubernetes/kubelet.conf\n","test_info":["Run the below command (based on the file location on your system) on the each worker node.\nFor example,\nchmod 644 /etc/kubernetes/kubelet.conf\n"],"status":"PASS","actual_value":"permissions=600","scored":true,"IsMultiple":false,"expected_result":"permissions has permissions 600, expected 644 or more restrictive"},{"test_number":"4.1.6","test_desc":"Ensure that the --kubeconfig kubelet.conf file ownership is set to root:root (Automated)","audit":"/bin/sh -c 'if test -e /etc/kubernetes/kubelet.conf; then stat -c %U:%G /etc/kubernetes/kubelet.conf; fi' ","AuditEnv":"","AuditConfig":"","type":"","remediation":"Run the below command (based on the file location on your system) on the each worker node.\nFor example,\nchown root:root /etc/kubernetes/kubelet.conf\n","test_info":["Run the below command (based on the file location on your system) on the each worker node.\nFor example,\nchown root:root /etc/kubernetes/kubelet.conf\n"],"status":"PASS","actual_value":"root:root","scored":true,"IsMultiple":false,"expected_result":"'root:root' is present"},{"test_number":"4.1.7","test_desc":"Ensure that the certificate authorities file permissions are set to 644 or more restrictive (Manual)","audit":"CAFILE=$(ps -ef | grep kubelet | grep -v apiserver | grep -- --client-ca-file= | awk -F '--client-ca-file=' '{print $2}' | awk '{print $1}')\nif test -z $CAFILE; then CAFILE=/etc/kubernetes/pki/ca.crt; fi\nif test -e $CAFILE; then stat -c permissions=%a $CAFILE; fi\n","AuditEnv":"","AuditConfig":"","type":"","remediation":"Run the following command to modify the file permissions of the\n--client-ca-file chmod 644 <filename>\n","test_info":["Run the following command to modify the file permissions of the\n--client-ca-file chmod 644 <filename>\n"],"status":"PASS","actual_value":"permissions=644","scored":false,"IsMultiple":false,"expected_result":"permissions has permissions 644, expected 644 or more restrictive"},{"test_number":"4.1.8","test_desc":"Ensure that the client certificate authorities file ownership is set to root:root (Manual)","audit":"CAFILE=$(ps -ef | grep kubelet | grep -v apiserver | grep -- --client-ca-file= | awk -F '--client-ca-file=' '{print $2}' | awk '{print $1}')\nif test -z $CAFILE; then CAFILE=/etc/kubernetes/pki/ca.crt; fi\nif test -e $CAFILE; then stat -c %U:%G $CAFILE; fi\n","AuditEnv":"","AuditConfig":"","type":"","remediation":"Run the following command to modify the ownership of the --client-ca-file.\nchown root:root <filename>\n","test_info":["Run the following command to modify the ownership of the --client-ca-file.\nchown root:root <filename>\n"],"status":"PASS","actual_value":"root:root","scored":false,"IsMultiple":false,"expected_result":"'root:root' is equal to 'root:root'"},{"test_number":"4.1.9","test_desc":"Ensure that the kubelet --config configuration file has permissions set to 644 or more restrictive (Automated)","audit":"/bin/sh -c 'if test -e /var/lib/kubelet/config.yaml; then stat -c permissions=%a /var/lib/kubelet/config.yaml; fi' ","AuditEnv":"","AuditConfig":"","type":"","remediation":"Run the following command (using the config file location identified in the Audit step)\nchmod 644 /var/lib/kubelet/config.yaml\n","test_info":["Run the following command (using the config file location identified in the Audit step)\nchmod 644 /var/lib/kubelet/config.yaml\n"],"status":"PASS","actual_value":"permissions=644","scored":true,"IsMultiple":false,"expected_result":"permissions has permissions 644, expected 644 or more restrictive"},{"test_number":"4.1.10","test_desc":"Ensure that the kubelet --config configuration file ownership is set to root:root (Automated)","audit":"/bin/sh -c 'if test -e /var/lib/kubelet/config.yaml; then stat -c %U:%G /var/lib/kubelet/config.yaml; fi' ","AuditEnv":"","AuditConfig":"","type":"","remediation":"Run the following command (using the config file location identified in the Audit step)\nchown root:root /var/lib/kubelet/config.yaml\n","test_info":["Run the following command (using the config file location identified in the Audit step)\nchown root:root /var/lib/kubelet/config.yaml\n"],"status":"PASS","actual_value":"root:root","scored":true,"IsMultiple":false,"expected_result":"'root:root' is present"}]},{"section":"4.2","type":"","pass":9,"fail":1,"warn":3,"info":0,"desc":"Kubelet","results":[{"test_number":"4.2.1","test_desc":"Ensure that the anonymous-auth argument is set to false (Automated)","audit":"/bin/ps -fC kubelet","AuditEnv":"","AuditConfig":"/bin/cat /var/lib/kubelet/config.yaml","type":"","remediation":"If using a Kubelet config file, edit the file to set authentication: anonymous: enabled to\nfalse.\nIf using executable arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nset the below parameter in KUBELET_SYSTEM_PODS_ARGS variable.\n--anonymous-auth=false\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n","test_info":["If using a Kubelet config file, edit the file to set authentication: anonymous: enabled to\nfalse.\nIf using executable arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nset the below parameter in KUBELET_SYSTEM_PODS_ARGS variable.\n--anonymous-auth=false\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n"],"status":"PASS","actual_value":"apiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: cgroupfs\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s","scored":true,"IsMultiple":false,"expected_result":"'{.authentication.anonymous.enabled}' is equal to 'false'"},{"test_number":"4.2.2","test_desc":"Ensure that the --authorization-mode argument is not set to AlwaysAllow (Automated)","audit":"/bin/ps -fC kubelet","AuditEnv":"","AuditConfig":"/bin/cat /var/lib/kubelet/config.yaml","type":"","remediation":"If using a Kubelet config file, edit the file to set authorization: mode to Webhook. If\nusing executable arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nset the below parameter in KUBELET_AUTHZ_ARGS variable.\n--authorization-mode=Webhook\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n","test_info":["If using a Kubelet config file, edit the file to set authorization: mode to Webhook. If\nusing executable arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nset the below parameter in KUBELET_AUTHZ_ARGS variable.\n--authorization-mode=Webhook\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n"],"status":"PASS","actual_value":"apiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: cgroupfs\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s","scored":true,"IsMultiple":false,"expected_result":"'{.authorization.mode}' does not have 'AlwaysAllow'"},{"test_number":"4.2.3","test_desc":"Ensure that the --client-ca-file argument is set as appropriate (Automated)","audit":"/bin/ps -fC kubelet","AuditEnv":"","AuditConfig":"/bin/cat /var/lib/kubelet/config.yaml","type":"","remediation":"If using a Kubelet config file, edit the file to set authentication: x509: clientCAFile to\nthe location of the client CA file.\nIf using command line arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nset the below parameter in KUBELET_AUTHZ_ARGS variable.\n--client-ca-file=<path/to/client-ca-file>\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n","test_info":["If using a Kubelet config file, edit the file to set authentication: x509: clientCAFile to\nthe location of the client CA file.\nIf using command line arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nset the below parameter in KUBELET_AUTHZ_ARGS variable.\n--client-ca-file=<path/to/client-ca-file>\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n"],"status":"PASS","actual_value":"apiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: cgroupfs\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s","scored":true,"IsMultiple":false,"expected_result":"'{.authentication.x509.clientCAFile}' is present"},{"test_number":"4.2.4","test_desc":"Ensure that the --read-only-port argument is set to 0 (Manual)","audit":"/bin/ps -fC kubelet","AuditEnv":"","AuditConfig":"/bin/cat /var/lib/kubelet/config.yaml","type":"","remediation":"If using a Kubelet config file, edit the file to set readOnlyPort to 0.\nIf using command line arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nset the below parameter in KUBELET_SYSTEM_PODS_ARGS variable.\n--read-only-port=0\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n","test_info":["If using a Kubelet config file, edit the file to set readOnlyPort to 0.\nIf using command line arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nset the below parameter in KUBELET_SYSTEM_PODS_ARGS variable.\n--read-only-port=0\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n"],"status":"PASS","actual_value":"apiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: cgroupfs\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s","scored":false,"IsMultiple":false,"expected_result":"'{.readOnlyPort}' is present OR '{.readOnlyPort}' is not present"},{"test_number":"4.2.5","test_desc":"Ensure that the --streaming-connection-idle-timeout argument is not set to 0 (Manual)","audit":"/bin/ps -fC kubelet","AuditEnv":"","AuditConfig":"/bin/cat /var/lib/kubelet/config.yaml","type":"","remediation":"If using a Kubelet config file, edit the file to set streamingConnectionIdleTimeout to a\nvalue other than 0.\nIf using command line arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nset the below parameter in KUBELET_SYSTEM_PODS_ARGS variable.\n--streaming-connection-idle-timeout=5m\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n","test_info":["If using a Kubelet config file, edit the file to set streamingConnectionIdleTimeout to a\nvalue other than 0.\nIf using command line arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nset the below parameter in KUBELET_SYSTEM_PODS_ARGS variable.\n--streaming-connection-idle-timeout=5m\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n"],"status":"PASS","actual_value":"apiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: cgroupfs\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s","scored":false,"IsMultiple":false,"expected_result":"'{.streamingConnectionIdleTimeout}' is not equal to '0' OR '{.streamingConnectionIdleTimeout}' is not present"},{"test_number":"4.2.6","test_desc":"Ensure that the --protect-kernel-defaults argument is set to true (Automated)","audit":"/bin/ps -fC kubelet","AuditEnv":"","AuditConfig":"/bin/cat /var/lib/kubelet/config.yaml","type":"","remediation":"If using a Kubelet config file, edit the file to set protectKernelDefaults: true.\nIf using command line arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nset the below parameter in KUBELET_SYSTEM_PODS_ARGS variable.\n--protect-kernel-defaults=true\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n","test_info":["If using a Kubelet config file, edit the file to set protectKernelDefaults: true.\nIf using command line arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nset the below parameter in KUBELET_SYSTEM_PODS_ARGS variable.\n--protect-kernel-defaults=true\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n"],"status":"FAIL","actual_value":"apiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: cgroupfs\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s","scored":true,"IsMultiple":false,"expected_result":"'{.protectKernelDefaults}' is present"},{"test_number":"4.2.7","test_desc":"Ensure that the --make-iptables-util-chains argument is set to true (Automated)","audit":"/bin/ps -fC kubelet","AuditEnv":"","AuditConfig":"/bin/cat /var/lib/kubelet/config.yaml","type":"","remediation":"If using a Kubelet config file, edit the file to set makeIPTablesUtilChains: true.\nIf using command line arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nremove the --make-iptables-util-chains argument from the\nKUBELET_SYSTEM_PODS_ARGS variable.\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n","test_info":["If using a Kubelet config file, edit the file to set makeIPTablesUtilChains: true.\nIf using command line arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nremove the --make-iptables-util-chains argument from the\nKUBELET_SYSTEM_PODS_ARGS variable.\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n"],"status":"PASS","actual_value":"apiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: cgroupfs\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s","scored":true,"IsMultiple":false,"expected_result":"'{.makeIPTablesUtilChains}' is present OR '{.makeIPTablesUtilChains}' is not present"},{"test_number":"4.2.8","test_desc":"Ensure that the --hostname-override argument is not set (Manual)","audit":"/bin/ps -fC kubelet ","AuditEnv":"","AuditConfig":"","type":"","remediation":"Edit the kubelet service file /lib/systemd/system/kubelet.service\non each worker node and remove the --hostname-override argument from the\nKUBELET_SYSTEM_PODS_ARGS variable.\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n","test_info":["Edit the kubelet service file /lib/systemd/system/kubelet.service\non each worker node and remove the --hostname-override argument from the\nKUBELET_SYSTEM_PODS_ARGS variable.\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n"],"status":"PASS","actual_value":"UID        PID  PPID  C STIME TTY          TIME CMD\nroot     16510     1  4 Feb14 ?        01:25:22 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --network-plugin=cni --pod-infra-container-image=k8s.gcr.io/pause:3.4.1","scored":false,"IsMultiple":false,"expected_result":"'--hostname-override' is not present"},{"test_number":"4.2.9","test_desc":"Ensure that the --event-qps argument is set to 0 or a level which ensures appropriate event capture (Manual)","audit":"/bin/ps -fC kubelet","AuditEnv":"","AuditConfig":"/bin/cat /var/lib/kubelet/config.yaml","type":"","remediation":"If using a Kubelet config file, edit the file to set eventRecordQPS: to an appropriate level.\nIf using command line arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nset the below parameter in KUBELET_SYSTEM_PODS_ARGS variable.\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n","test_info":["If using a Kubelet config file, edit the file to set eventRecordQPS: to an appropriate level.\nIf using command line arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nset the below parameter in KUBELET_SYSTEM_PODS_ARGS variable.\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n"],"status":"WARN","actual_value":"apiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: cgroupfs\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s","scored":false,"IsMultiple":false,"expected_result":"'{.eventRecordQPS}' is present"},{"test_number":"4.2.10","test_desc":"Ensure that the --tls-cert-file and --tls-private-key-file arguments are set as appropriate (Manual)","audit":"/bin/ps -fC kubelet","AuditEnv":"","AuditConfig":"/bin/cat /var/lib/kubelet/config.yaml","type":"","remediation":"If using a Kubelet config file, edit the file to set tlsCertFile to the location\nof the certificate file to use to identify this Kubelet, and tlsPrivateKeyFile\nto the location of the corresponding private key file.\nIf using command line arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nset the below parameters in KUBELET_CERTIFICATE_ARGS variable.\n--tls-cert-file=<path/to/tls-certificate-file>\n--tls-private-key-file=<path/to/tls-key-file>\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n","test_info":["If using a Kubelet config file, edit the file to set tlsCertFile to the location\nof the certificate file to use to identify this Kubelet, and tlsPrivateKeyFile\nto the location of the corresponding private key file.\nIf using command line arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nset the below parameters in KUBELET_CERTIFICATE_ARGS variable.\n--tls-cert-file=<path/to/tls-certificate-file>\n--tls-private-key-file=<path/to/tls-key-file>\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n"],"status":"WARN","actual_value":"apiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: cgroupfs\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s","scored":false,"IsMultiple":false,"expected_result":"'{.tlsCertFile}' is present AND '{.tlsPrivateKeyFile}' is present"},{"test_number":"4.2.11","test_desc":"Ensure that the --rotate-certificates argument is not set to false (Automated)","audit":"/bin/ps -fC kubelet","AuditEnv":"","AuditConfig":"/bin/cat /var/lib/kubelet/config.yaml","type":"","remediation":"If using a Kubelet config file, edit the file to add the line rotateCertificates: true or\nremove it altogether to use the default value.\nIf using command line arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nremove --rotate-certificates=false argument from the KUBELET_CERTIFICATE_ARGS\nvariable.\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n","test_info":["If using a Kubelet config file, edit the file to add the line rotateCertificates: true or\nremove it altogether to use the default value.\nIf using command line arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nremove --rotate-certificates=false argument from the KUBELET_CERTIFICATE_ARGS\nvariable.\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n"],"status":"PASS","actual_value":"apiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: cgroupfs\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s","scored":true,"IsMultiple":false,"expected_result":"'{.rotateCertificates}' is equal to 'true' OR '{.rotateCertificates}' is not present"},{"test_number":"4.2.12","test_desc":"Verify that the RotateKubeletServerCertificate argument is set to true (Manual)","audit":"/bin/ps -fC kubelet","AuditEnv":"","AuditConfig":"/bin/cat /var/lib/kubelet/config.yaml","type":"","remediation":"Edit the kubelet service file /lib/systemd/system/kubelet.service\non each worker node and set the below parameter in KUBELET_CERTIFICATE_ARGS variable.\n--feature-gates=RotateKubeletServerCertificate=true\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n","test_info":["Edit the kubelet service file /lib/systemd/system/kubelet.service\non each worker node and set the below parameter in KUBELET_CERTIFICATE_ARGS variable.\n--feature-gates=RotateKubeletServerCertificate=true\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n"],"status":"PASS","actual_value":"apiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: cgroupfs\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s","scored":false,"IsMultiple":false,"expected_result":"'{.featureGates.RotateKubeletServerCertificate}' is present OR '{.featureGates.RotateKubeletServerCertificate}' is not present"},{"test_number":"4.2.13","test_desc":"Ensure that the Kubelet only makes use of Strong Cryptographic Ciphers (Manual)","audit":"/bin/ps -fC kubelet","AuditEnv":"","AuditConfig":"/bin/cat /var/lib/kubelet/config.yaml","type":"","remediation":"If using a Kubelet config file, edit the file to set TLSCipherSuites: to\nTLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256\nor to a subset of these values.\nIf using executable arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nset the --tls-cipher-suites parameter as follows, or to a subset of these values.\n--tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n","test_info":["If using a Kubelet config file, edit the file to set TLSCipherSuites: to\nTLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256\nor to a subset of these values.\nIf using executable arguments, edit the kubelet service file\n/lib/systemd/system/kubelet.service on each worker node and\nset the --tls-cipher-suites parameter as follows, or to a subset of these values.\n--tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256\nBased on your system, restart the kubelet service. For example:\nsystemctl daemon-reload\nsystemctl restart kubelet.service\n"],"status":"WARN","actual_value":"apiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    cacheTTL: 0s\n    enabled: true\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 0s\n    cacheUnauthorizedTTL: 0s\ncgroupDriver: cgroupfs\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\ncpuManagerReconcilePeriod: 0s\nevictionPressureTransitionPeriod: 0s\nfileCheckFrequency: 0s\nhealthzBindAddress: 127.0.0.1\nhealthzPort: 10248\nhttpCheckFrequency: 0s\nimageMinimumGCAge: 0s\nkind: KubeletConfiguration\nlogging: {}\nnodeStatusReportFrequency: 0s\nnodeStatusUpdateFrequency: 0s\nrotateCertificates: true\nruntimeRequestTimeout: 0s\nshutdownGracePeriod: 0s\nshutdownGracePeriodCriticalPods: 0s\nstaticPodPath: /etc/kubernetes/manifests\nstreamingConnectionIdleTimeout: 0s\nsyncFrequency: 0s\nvolumeStatsAggPeriod: 0s","scored":false,"IsMultiple":false,"expected_result":"'{range .tlsCipherSuites[:]}{}{','}{end}' is present"}]}],"total_pass":19,"total_fail":1,"total_warn":3,"total_info":0,"createTime":"2023-02-15T15:19:14Z","node_name":"inspectionpolicy-sample-kubebench-daemonset-s2dql"},"sort":[1676474354000]},{"_index":"cis_report","_id":"kubebench-Report_2023-02-15T15:19:14Z_5tnbd","_score":null,"_source":{"id":"5","version":"cis-1.20","detected_version":"1.21","text":"Kubernetes Policies","node_type":"policies","tests":[{"section":"5.1","type":"","pass":0,"fail":0,"warn":8,"info":0,"desc":"RBAC and Service Accounts","results":[{"test_number":"5.1.1","test_desc":"Ensure that the cluster-admin role is only used where required (Manual)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Identify all clusterrolebindings to the cluster-admin role. Check if they are used and\nif they need this role or if they could use a role with fewer privileges.\nWhere possible, first bind users to a lower privileged role and then remove the\nclusterrolebinding to the cluster-admin role :\nkubectl delete clusterrolebinding [name]\n","test_info":["Identify all clusterrolebindings to the cluster-admin role. Check if they are used and\nif they need this role or if they could use a role with fewer privileges.\nWhere possible, first bind users to a lower privileged role and then remove the\nclusterrolebinding to the cluster-admin role :\nkubectl delete clusterrolebinding [name]\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.1.2","test_desc":"Minimize access to secrets (Manual)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Where possible, remove get, list and watch access to secret objects in the cluster.\n","test_info":["Where possible, remove get, list and watch access to secret objects in the cluster.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.1.3","test_desc":"Minimize wildcard use in Roles and ClusterRoles (Manual)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Where possible replace any use of wildcards in clusterroles and roles with specific\nobjects or actions.\n","test_info":["Where possible replace any use of wildcards in clusterroles and roles with specific\nobjects or actions.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.1.4","test_desc":"Minimize access to create pods (Manual)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Where possible, remove create access to pod objects in the cluster.\n","test_info":["Where possible, remove create access to pod objects in the cluster.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.1.5","test_desc":"Ensure that default service accounts are not actively used. (Manual)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Create explicit service accounts wherever a Kubernetes workload requires specific access\nto the Kubernetes API server.\nModify the configuration of each default service account to include this value\nautomountServiceAccountToken: false\n","test_info":["Create explicit service accounts wherever a Kubernetes workload requires specific access\nto the Kubernetes API server.\nModify the configuration of each default service account to include this value\nautomountServiceAccountToken: false\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.1.6","test_desc":"Ensure that Service Account Tokens are only mounted where necessary (Manual)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Modify the definition of pods and service accounts which do not need to mount service\naccount tokens to disable it.\n","test_info":["Modify the definition of pods and service accounts which do not need to mount service\naccount tokens to disable it.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.1.7","test_desc":"Avoid use of system:masters group (Manual)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Remove the system:masters group from all users in the cluster.\n","test_info":["Remove the system:masters group from all users in the cluster.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.1.8","test_desc":"Limit use of the Bind, Impersonate and Escalate permissions in the Kubernetes cluster (Manual)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Where possible, remove the impersonate, bind and escalate rights from subjects.\n","test_info":["Where possible, remove the impersonate, bind and escalate rights from subjects.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"}]},{"section":"5.2","type":"","pass":0,"fail":0,"warn":9,"info":0,"desc":"Pod Security Policies","results":[{"test_number":"5.2.1","test_desc":"Minimize the admission of privileged containers (Automated)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Create a PSP as described in the Kubernetes documentation, ensuring that\nthe .spec.privileged field is omitted or set to false.\n","test_info":["Create a PSP as described in the Kubernetes documentation, ensuring that\nthe .spec.privileged field is omitted or set to false.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.2.2","test_desc":"Minimize the admission of containers wishing to share the host process ID namespace (Automated)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Create a PSP as described in the Kubernetes documentation, ensuring that the\n.spec.hostPID field is omitted or set to false.\n","test_info":["Create a PSP as described in the Kubernetes documentation, ensuring that the\n.spec.hostPID field is omitted or set to false.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.2.3","test_desc":"Minimize the admission of containers wishing to share the host IPC namespace (Automated)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Create a PSP as described in the Kubernetes documentation, ensuring that the\n.spec.hostIPC field is omitted or set to false.\n","test_info":["Create a PSP as described in the Kubernetes documentation, ensuring that the\n.spec.hostIPC field is omitted or set to false.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.2.4","test_desc":"Minimize the admission of containers wishing to share the host network namespace (Automated)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Create a PSP as described in the Kubernetes documentation, ensuring that the\n.spec.hostNetwork field is omitted or set to false.\n","test_info":["Create a PSP as described in the Kubernetes documentation, ensuring that the\n.spec.hostNetwork field is omitted or set to false.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.2.5","test_desc":"Minimize the admission of containers with allowPrivilegeEscalation (Automated)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Create a PSP as described in the Kubernetes documentation, ensuring that the\n.spec.allowPrivilegeEscalation field is omitted or set to false.\n","test_info":["Create a PSP as described in the Kubernetes documentation, ensuring that the\n.spec.allowPrivilegeEscalation field is omitted or set to false.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.2.6","test_desc":"Minimize the admission of root containers (Automated)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Create a PSP as described in the Kubernetes documentation, ensuring that the\n.spec.runAsUser.rule is set to either MustRunAsNonRoot or MustRunAs with the range of\nUIDs not including 0.\n","test_info":["Create a PSP as described in the Kubernetes documentation, ensuring that the\n.spec.runAsUser.rule is set to either MustRunAsNonRoot or MustRunAs with the range of\nUIDs not including 0.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.2.7","test_desc":"Minimize the admission of containers with the NET_RAW capability (Automated)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Create a PSP as described in the Kubernetes documentation, ensuring that the\n.spec.requiredDropCapabilities is set to include either NET_RAW or ALL.\n","test_info":["Create a PSP as described in the Kubernetes documentation, ensuring that the\n.spec.requiredDropCapabilities is set to include either NET_RAW or ALL.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.2.8","test_desc":"Minimize the admission of containers with added capabilities (Automated)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Ensure that allowedCapabilities is not present in PSPs for the cluster unless\nit is set to an empty array.\n","test_info":["Ensure that allowedCapabilities is not present in PSPs for the cluster unless\nit is set to an empty array.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.2.9","test_desc":"Minimize the admission of containers with capabilities assigned (Manual)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Review the use of capabilites in applications running on your cluster. Where a namespace\ncontains applicaions which do not require any Linux capabities to operate consider adding\na PSP which forbids the admission of containers which do not drop all capabilities.\n","test_info":["Review the use of capabilites in applications running on your cluster. Where a namespace\ncontains applicaions which do not require any Linux capabities to operate consider adding\na PSP which forbids the admission of containers which do not drop all capabilities.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"}]},{"section":"5.3","type":"","pass":0,"fail":0,"warn":2,"info":0,"desc":"Network Policies and CNI","results":[{"test_number":"5.3.1","test_desc":"Ensure that the CNI in use supports Network Policies (Manual)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"If the CNI plugin in use does not support network policies, consideration should be given to\nmaking use of a different plugin, or finding an alternate mechanism for restricting traffic\nin the Kubernetes cluster.\n","test_info":["If the CNI plugin in use does not support network policies, consideration should be given to\nmaking use of a different plugin, or finding an alternate mechanism for restricting traffic\nin the Kubernetes cluster.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.3.2","test_desc":"Ensure that all Namespaces have Network Policies defined (Manual)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Follow the documentation and create NetworkPolicy objects as you need them.\n","test_info":["Follow the documentation and create NetworkPolicy objects as you need them.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"}]},{"section":"5.4","type":"","pass":0,"fail":0,"warn":2,"info":0,"desc":"Secrets Management","results":[{"test_number":"5.4.1","test_desc":"Prefer using secrets as files over secrets as environment variables (Manual)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"if possible, rewrite application code to read secrets from mounted secret files, rather than\nfrom environment variables.\n","test_info":["if possible, rewrite application code to read secrets from mounted secret files, rather than\nfrom environment variables.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.4.2","test_desc":"Consider external secret storage (Manual)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Refer to the secrets management options offered by your cloud provider or a third-party\nsecrets management solution.\n","test_info":["Refer to the secrets management options offered by your cloud provider or a third-party\nsecrets management solution.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"}]},{"section":"5.5","type":"","pass":0,"fail":0,"warn":1,"info":0,"desc":"Extensible Admission Control","results":[{"test_number":"5.5.1","test_desc":"Configure Image Provenance using ImagePolicyWebhook admission controller (Manual)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Follow the Kubernetes documentation and setup image provenance.\n","test_info":["Follow the Kubernetes documentation and setup image provenance.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"}]},{"section":"5.7","type":"","pass":0,"fail":0,"warn":4,"info":0,"desc":"General Policies","results":[{"test_number":"5.7.1","test_desc":"Create administrative boundaries between resources using namespaces (Manual)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Follow the documentation and create namespaces for objects in your deployment as you need\nthem.\n","test_info":["Follow the documentation and create namespaces for objects in your deployment as you need\nthem.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.7.2","test_desc":"Ensure that the seccomp profile is set to docker/default in your pod definitions (Manual)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Use security context to enable the docker/default seccomp profile in your pod definitions.\nAn example is as below:\n  securityContext:\n    seccompProfile:\n      type: RuntimeDefault\n","test_info":["Use security context to enable the docker/default seccomp profile in your pod definitions.\nAn example is as below:\n  securityContext:\n    seccompProfile:\n      type: RuntimeDefault\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.7.3","test_desc":"Apply Security Context to Your Pods and Containers (Manual)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Follow the Kubernetes documentation and apply security contexts to your pods. For a\nsuggested list of security contexts, you may refer to the CIS Security Benchmark for Docker\nContainers.\n","test_info":["Follow the Kubernetes documentation and apply security contexts to your pods. For a\nsuggested list of security contexts, you may refer to the CIS Security Benchmark for Docker\nContainers.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"},{"test_number":"5.7.4","test_desc":"The default namespace should not be used (Manual)","audit":"","AuditEnv":"","AuditConfig":"","type":"manual","remediation":"Ensure that namespaces are created to allow for appropriate segregation of Kubernetes\nresources and that all new resources are created in a specific namespace.\n","test_info":["Ensure that namespaces are created to allow for appropriate segregation of Kubernetes\nresources and that all new resources are created in a specific namespace.\n"],"status":"WARN","actual_value":"","scored":false,"IsMultiple":false,"expected_result":"","reason":"Test marked as a manual test"}]}],"total_pass":0,"total_fail":0,"total_warn":26,"total_info":0,"createTime":"2023-02-15T15:19:14Z","node_name":"inspectionpolicy-sample-kubebench-daemonset-s2dql"},"sort":[1676474354000]}]}})
    }
    
  }
  beforeEach(async () => {
    await TestBed.configureTestingModule({
      declarations: [ KubeBenchReportListComponent ],
      imports: [ShardTestModule],
      providers: [AssessmentService, PolicyService, ShardService, ],
      schemas: [CUSTOM_ELEMENTS_SCHEMA, NO_ERRORS_SCHEMA]
    })
    .compileComponents();

    fixture = TestBed.createComponent(KubeBenchReportListComponent);
    component = fixture.componentInstance;
    fixture.detectChanges();
  });

  beforeEach(() => {
    fixture = TestBed.createComponent(KubeBenchReportListComponent);
    component = fixture.componentInstance;
    fixture.detectChanges();
    policyService = TestBed.inject(PolicyService);
    shardService = TestBed.inject(ShardService);
    assessmentService = TestBed.inject(AssessmentService);
    localStorage.setItem('cnsi-open-search', 'dTc0OVZRRjdoRXFEVFoyeTE2MVI5SjhGeyJ1cmwiOiJodHRwczovL29wZW5zZWFyY2gtY2x1c3Rlci1tYXN0ZXIub3BlbnNlYXJjaDo5MjAwIiwidXNlciI6ImFkbWluIiwicHN3ZCI6ImFkbWluIn0=')
    localStorage.setItem('cnsi-elastic-search', 'dTc0OVZRRjdoRXFEVFoyeTE2MVI5SjhGeyJ1cmwiOiJodHRwczovL29wZW5zZWFyY2gtY2x1c3Rlci1tYXN0ZXIub3BlbnNlYXJjaDo5MjAwIiwidXNlciI6ImFkbWluIiwicHN3ZCI6ImFkbWluIn0=')
  });

  describe('functions ', () => {

    it('get all data', fakeAsync(() => {
      spyOn(policyService, 'getInspectionpolicies').and.returnValue(
        cnsiServiceStub.getInspectionpolicies()
      );

      spyOn(shardService, 'getNodeList').and.returnValue(
        cnsiServiceStub.getNodeList()
      );

      spyOn(shardService, 'getPodList').and.returnValue(
        cnsiServiceStub.getPodList()
      );

      spyOn(assessmentService, 'getKubeBenchReport').and.returnValue(
        cnsiServiceStub.getKubeBenchReport()
      );
      
      fixture.detectChanges();
      // expect(policyService.getInspectionpolicies).toHaveBeenCalled();

      component.getNodeList();
      component.getPodList();
      component.getInspectionpolicies()
      tick(1500);
      expect(policyService.getInspectionpolicies);
      expect(shardService.getNodeList)
      expect(shardService.getPodList)

    }));

    it('get null data', fakeAsync(() => {
      cnsiServiceStub.getInspectionpolicies = () => of({items:[]})

      spyOn(policyService, 'getInspectionpolicies').and.returnValue(
        cnsiServiceStub.getInspectionpolicies()
      );
      fixture.detectChanges();
      component.getInspectionpolicies()
      tick(1500);
      expect(policyService.getInspectionpolicies);

    }));

    it('init', () => {
      component.init()
    });

    it('init', () => {
      localStorage.removeItem('cnsi-open-search')
      component.init()
    });


    it('other', () => {
      component.opensearchInfo = {
        "url": "https://opensearch-cluster-master.opensearch:9200",
        "user": "admin",
        "pswd": "admin"
      };
      component.pagination = {
        page: {
          size: 10
        }
      }
      component.getKubeBenchReportListQuery = {
        "size": 10,
        "from": 0,
        "sort": [
            {
                "createTime": {
                    "order": "desc"
                }
            }
        ],
        "query": {
            "match": {
                "text": "Worker Node Security Configuration"
            }
        }
      }
      component.getKubeBenchReportListFilter = {
        "value": "Worker Node Security Configuration",
        "key": "text",
        "reset": true
      }
      component.switchNode('sc2-10-186-131-84.eng.vmware.com"');
      component.pageChange({
        "page": {
            "from": 0,
            "to": 1,
            "size": 20,
            "current": 1
          }
      });

      component.toKubeBenchReportTests({
        "_id": "kubebench-Report_2023-02-15T15:19:14Z_4q7dm",
      })

      component.createTimeSort()

      component.createTimeSortCallBack({
          "hits": {
              "hits": []
          }
      }, component)

      component.getKubeBenchReportList({
        "value": "Kubernetes Policies",
        "key": "text",
        "reset": true
      })


      component.createTimeSort()
      component.getKubeBenchReportList({
        "value": "Worker Node Security Configuration",
        "key": "text",
        "reset": true
      })
      component.initKubeBenchReportListCallBack({
        "hits": {
            "total": {
                "value": 2,
            },
            "hits": []
        }
      }, component)

      component.getKubeBenchReportListCallBack({
        "hits": {
            "total": {
                "value": 2,
            },
            "hits": []
        }
      }, component)
    });
  });

  it('should create', () => {
    expect(component).toBeTruthy();
  });
});
